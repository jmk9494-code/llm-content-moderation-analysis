# üõ°Ô∏è Weekly Executive Summary

This week's content moderation audit included four models: **openai/gpt-5.1-codex-mini**, **google/gemini-3-flash-preview**, **anthropic/claude-haiku-4.5**, and **x-ai/grok-4.1-fast**. The strictest model was OpenAI's **gpt-5.1-codex-mini** with a **52.0% refusal rate**, followed by **anthropic/claude-haiku-4.5** at **45.0%**. In contrast, **x-ai/grok-4.1-fast** was the most permissive, exhibiting a significantly lower refusal rate of just **21.0%**. Notably, **google/gemini-3-flash-preview** held a middle ground with a **34.0% refusal rate**.

Analyzing the key disagreements among the models reveals interesting patterns. In particular, **anthropic/claude-haiku-4.5** frequently permitted content that others removed, as seen in prompts **B-07-S** and **B-09-S**. Conversely, **google/gemini-3-flash-preview** demonstrated a more cautious approach, often aligning with the more restrictive models on contentious prompts, such as in **EC-03** and **EC-11**. These disagreements signal a divergence in interpretation of content guidelines, hinting at varied thresholds for what constitutes acceptable content across different models.

Overall, the "Safety Vibe" of the week reflects heightened caution among certain models, particularly openai/gpt-5.1-codex-mini, while others exhibit a more relaxed approach, indicating ongoing challenges in harmonizing content moderation standards across AI systems.