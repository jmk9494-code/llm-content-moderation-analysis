# üõ°Ô∏è Weekly Executive Summary

In this week's content moderation audit of four AI models, we observed varying refusal rates indicative of their strictness in content moderation. The **strictest model** was **anthropic/claude-haiku-4.5** with a **36.4% refusal rate**, followed closely by **openai/gpt-5.1-codex-mini** at **32.0%**. In contrast, the **most permissible model** was **x-ai/grok-4.1-fast**, exhibiting a significantly lower refusal rate of **7.4%**, while **google/gemini-3-flash-preview** held a moderate position at **11.5%**.

Examining the **key disagreements** among the models, we noted that inconsistencies mainly arose in prompts that touched on sensitive socio-political topics, where the stricter models opted for refusal while the more permissible models provided responses. This divergence suggests a substantial variance in how these models interpret the boundaries of acceptable discourse.

Overall, the "Safety Vibe" of the week demonstrates a strong commitment to cautious moderation among models, particularly those like **anthropic/claude-haiku-4.5** and **openai/gpt-5.1-codex-mini**, emphasizing a nuanced approach to handling potential sensitivities in user prompts.