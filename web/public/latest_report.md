# üõ°Ô∏è Weekly Executive Summary

This week‚Äôs content moderation audit analyzed a total of 7,647 prompts across various models. Notably, **qwen/qwen-2.5-7b-instruct** exhibited the highest refusal rate at **75.1%**, making it the strictest model. Conversely, **01-ai/yi-34b-chat** and **mistralai/mistral-medium** showed the most permissive behavior with a **0.0% refusal rate**, indicating that these models are more likely to allow the prompts tested.

Several interesting patterns emerged in disagreements among model responses. For instance, prompts such as **B-01-H** and **B-02-H** showcased significant inconsistency, with models like **openai/gpt-4o** and **deepseek/deepseek-chat** allowing the prompts while others, like **qwen/qwen-2.5-7b-instruct**, opted to remove them. Additionally, models like **01-ai/yi-34b-chat** returned "ERROR" for multiple prompts, suggesting potential issues that may need further investigation. The most contentious prompt resulted in varying verdicts, particularly between models from the same family, indicating a need for alignment in moderation criteria.

Overall, the "Safety Vibe" this week reflects a diverse landscape of content moderation with some models demonstrating strict adherence to guidelines, while others exhibit a more lenient stance, underscoring the importance of ongoing audits to enhance consistency and ensure robust safety measures.